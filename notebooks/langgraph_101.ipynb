{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b64b8fdf",
   "metadata": {},
   "source": [
    "# LangGraph 101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0652e3",
   "metadata": {},
   "source": [
    "Les LLMs (Large Language Models) permettent d’intégrer de l’intelligence dans une nouvelle génération d’applications. LangGraph est un framework conçu pour aider à construire ces applications basées sur les LLMs.\n",
    "\n",
    "Dans cette introduction, nous allons :\n",
    "\n",
    "1. passer en revue les bases de LangGraph,\n",
    "\n",
    "2. expliquer ses avantages,\n",
    "\n",
    "3. montrer comment l’utiliser pour créer des workflows et des agents,\n",
    "\n",
    "4. et enfin expliquer son fonctionnement avec LangChain et LangSmith.\n",
    "\n",
    "![ecosystem](./img/ecosystem.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad14578",
   "metadata": {},
   "source": [
    "# Modèles de chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008bd925",
   "metadata": {},
   "source": [
    "Les modèles de chat sont la base des applications LLM. Ils sont généralement accessibles via une interface de chat qui prend en entrée une liste de messages et renvoie en sortie un message. **LangChain** fournit une interface standardisée pour les modèles de chat, ce qui facilite l’accès à de nombreux fournisseurs différents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6fa9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da7a3b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"openai:gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0c9258",
   "metadata": {},
   "source": [
    "## Exécution du modèle\n",
    "\n",
    "L’interface `init_chat_model` fournit des méthodes standardisées pour utiliser les modèles de chat, notamment :\n",
    "\n",
    "* `invoke()` : une seule entrée est transformée en une sortie.\n",
    "\n",
    "* `stream()` : les sorties sont transmises en flux au fur et à mesure de leur production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "976cf8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(\"Qu'est qu'un agent en IA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "155b7573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dee8dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Un agent en intelligence artificielle (IA) est un système capable de percevoir son environnement, de traiter des   \n",
       "informations et de prendre des décisions ou d'agir en conséquence. Les agents peuvent être simples ou complexes,   \n",
       "allant de programmes informatiques qui effectuent des tâches spécifiques à des systèmes autonomes plus avancés,    \n",
       "comme des robots ou des assistants virtuels.                                                                       \n",
       "\n",
       "Voici quelques caractéristiques clés d'un agent en IA :                                                            \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Perception</span> : Un agent peut recueillir des données sur son environnement à l'aide de capteurs ou d'autres moyens \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>d'entrée. Cela peut inclure des données visuelles, sonores, ou d'autres types d'informations.                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Raisonnement</span> : Un agent utilise des algorithmes et des modèles pour analyser les données perçues, évaluer des   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>options et prendre des décisions. Cela peut impliquer des techniques d'apprentissage automatique, de logique, ou\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>d'optimisation.                                                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">Action</span> : Après avoir pris une décision, un agent agit sur son environnement. Cela peut impliquer des actions    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>physiques (comme un robot qui se déplace) ou des actions logiques (comme un programme qui envoie un message).   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">Autonomie</span> : Certains agents sont conçus pour fonctionner de manière autonome, sans intervention humaine, tandis \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>que d'autres peuvent nécessiter une supervision ou des instructions.                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 5 </span><span style=\"font-weight: bold\">Interaction</span> : Les agents peuvent interagir avec d'autres agents ou avec des utilisateurs humains, ce qui peut   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>inclure la communication, la collaboration ou la compétition.                                                   \n",
       "\n",
       "Les agents en IA sont utilisés dans de nombreux domaines, y compris la robotique, les systèmes de recommandation,  \n",
       "les jeux vidéo, les assistants virtuels (comme Siri ou Alexa), et bien d'autres applications.                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Un agent en intelligence artificielle (IA) est un système capable de percevoir son environnement, de traiter des   \n",
       "informations et de prendre des décisions ou d'agir en conséquence. Les agents peuvent être simples ou complexes,   \n",
       "allant de programmes informatiques qui effectuent des tâches spécifiques à des systèmes autonomes plus avancés,    \n",
       "comme des robots ou des assistants virtuels.                                                                       \n",
       "\n",
       "Voici quelques caractéristiques clés d'un agent en IA :                                                            \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mPerception\u001b[0m : Un agent peut recueillir des données sur son environnement à l'aide de capteurs ou d'autres moyens \n",
       "\u001b[1;33m   \u001b[0md'entrée. Cela peut inclure des données visuelles, sonores, ou d'autres types d'informations.                   \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mRaisonnement\u001b[0m : Un agent utilise des algorithmes et des modèles pour analyser les données perçues, évaluer des   \n",
       "\u001b[1;33m   \u001b[0moptions et prendre des décisions. Cela peut impliquer des techniques d'apprentissage automatique, de logique, ou\n",
       "\u001b[1;33m   \u001b[0md'optimisation.                                                                                                 \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mAction\u001b[0m : Après avoir pris une décision, un agent agit sur son environnement. Cela peut impliquer des actions    \n",
       "\u001b[1;33m   \u001b[0mphysiques (comme un robot qui se déplace) ou des actions logiques (comme un programme qui envoie un message).   \n",
       "\u001b[1;33m 4 \u001b[0m\u001b[1mAutonomie\u001b[0m : Certains agents sont conçus pour fonctionner de manière autonome, sans intervention humaine, tandis \n",
       "\u001b[1;33m   \u001b[0mque d'autres peuvent nécessiter une supervision ou des instructions.                                            \n",
       "\u001b[1;33m 5 \u001b[0m\u001b[1mInteraction\u001b[0m : Les agents peuvent interagir avec d'autres agents ou avec des utilisateurs humains, ce qui peut   \n",
       "\u001b[1;33m   \u001b[0minclure la communication, la collaboration ou la compétition.                                                   \n",
       "\n",
       "Les agents en IA sont utilisés dans de nombreux domaines, y compris la robotique, les systèmes de recommandation,  \n",
       "les jeux vidéo, les assistants virtuels (comme Siri ou Alexa), et bien d'autres applications.                      \n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rich.markdown import Markdown\n",
    "Markdown(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6e9972",
   "metadata": {},
   "source": [
    "## Outils (Tools)\n",
    "\n",
    "Les outils sont des utilitaires qui peuvent être appelés par un modèle de chat. Dans LangChain, la création d’outils peut se faire grâce au décorateur `@tool`, qui transforme des fonctions Python en outils appelables. Le décorateur déduit automatiquement le nom de l’outil, sa description et les arguments attendus à partir de la définition de la fonction. Il est également possible d’utiliser des serveurs **MCP (Model Context Protocol)** comme outils compatibles avec LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "617a3ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Write and send an email.\"\"\"\n",
    "    # Placeholder response - in real app would send email\n",
    "    return f\"Email sent to {to} with subject '{subject}' and content: {content}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "186ee7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.tools.structured.StructuredTool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(write_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f61949ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': {'title': 'To', 'type': 'string'},\n",
       " 'subject': {'title': 'Subject', 'type': 'string'},\n",
       " 'content': {'title': 'Content', 'type': 'string'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_email.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "989a8196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Write and send an email.                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Write and send an email.                                                                                           \n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(write_email.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9935d6b5",
   "metadata": {},
   "source": [
    "## Appel d’outils (Tool Calling)\n",
    "\n",
    "Les outils peuvent être appelés par les LLMs. Lorsqu’un outil est lié au modèle, celui-ci peut choisir de l’appeler en renvoyant une sortie structurée avec les arguments de l’outil. Nous utilisons la méthode `bind_tools` pour enrichir un LLM avec des outils.\n",
    "\n",
    "![tool-img](img/tool_call_detail.png)\n",
    "\n",
    "Les fournisseurs proposent souvent des paramètres comme `tool_choice` pour imposer l’appel d’outils spécifiques. L’option `any` sélectionnera au moins un des outils.\n",
    "\n",
    "De plus, il est possible de définir `parallel_tool_calls=False` afin de s’assurer que le modèle n’appelle qu’un seul outil à la fois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "744361ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecter des outils à un modèle de chat\n",
    "model_with_tools = llm.bind_tools([write_email], tool_choice=\"any\", parallel_tool_calls=False)\n",
    "\n",
    "# Le modèle peut maintenant appeler les outils\n",
    "output = model_with_tools.invoke(\"Rédige une réponse à mon patron (boss@company.ai) concernant la réunion de demain\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6a81451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63c86f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': 'boss@company.ai',\n",
       " 'subject': 'Réunion de demain',\n",
       " 'content': \"Bonjour,\\n\\nMerci pour l'invitation à la réunion de demain. Je serai présent et prêt à discuter des points à l'ordre du jour. Si vous avez des documents ou des informations supplémentaires à partager avant la réunion, n'hésitez pas à me les envoyer.\\n\\nCordialement,\\n\\n[Votre Nom]\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract tool calls and execute them\n",
    "args = output.tool_calls[0]['args']\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d38762b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'write_email',\n",
       "  'args': {'to': 'boss@company.ai',\n",
       "   'subject': 'Réunion de demain',\n",
       "   'content': \"Bonjour,\\n\\nMerci pour l'invitation à la réunion de demain. Je serai présent et prêt à discuter des points à l'ordre du jour. Si vous avez des documents ou des informations supplémentaires à partager avant la réunion, n'hésitez pas à me les envoyer.\\n\\nCordialement,\\n\\n[Votre Nom]\"},\n",
       "  'id': 'call_ztt1urmmAGO9bza7SOTQfzet',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98526d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Email sent to boss@company.ai with subject 'Réunion de demain' and content: Bonjour,                               \n",
       "\n",
       "Merci pour l'invitation à la réunion de demain. Je serai présent et prêt à discuter des points à l'ordre du jour.  \n",
       "Si vous avez des documents ou des informations supplémentaires à partager avant la réunion, n'hésitez pas à me les \n",
       "envoyer.                                                                                                           \n",
       "\n",
       "Cordialement,                                                                                                      \n",
       "\n",
       "[Votre Nom]                                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Email sent to boss@company.ai with subject 'Réunion de demain' and content: Bonjour,                               \n",
       "\n",
       "Merci pour l'invitation à la réunion de demain. Je serai présent et prêt à discuter des points à l'ordre du jour.  \n",
       "Si vous avez des documents ou des informations supplémentaires à partager avant la réunion, n'hésitez pas à me les \n",
       "envoyer.                                                                                                           \n",
       "\n",
       "Cordialement,                                                                                                      \n",
       "\n",
       "[Votre Nom]                                                                                                        \n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the tool\n",
    "result = write_email.invoke(args)\n",
    "Markdown(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b1c251",
   "metadata": {},
   "source": [
    "### Explication\n",
    "Accéder aux informations d'une liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a012dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_calls = [\n",
    "    {\n",
    "        'name': 'write_email',\n",
    "        'args': {\n",
    "            'to': 'boss@company.ai',\n",
    "            'subject': 'Réunion de demain',\n",
    "            'content': \"Bonjour,\\n\\nMerci pour l'invitation à la réunion de demain. Je serai présent et prêt à discuter des points à l'ordre du jour. Si vous avez des documents ou des informations supplémentaires à partager avant la réunion, n'hésitez pas à me les envoyer.\\n\\nCordialement,\\n\\n[Votre Nom]\"\n",
    "        },\n",
    "        'id': 'call_ztt1urmmAGO9bza7SOTQfzet',\n",
    "        'type': 'tool_call'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ead9ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'to': 'boss@company.ai', 'subject': 'Réunion de demain', 'content': \"Bonjour,\\n\\nMerci pour l'invitation à la réunion de demain. Je serai présent et prêt à discuter des points à l'ordre du jour. Si vous avez des documents ou des informations supplémentaires à partager avant la réunion, n'hésitez pas à me les envoyer.\\n\\nCordialement,\\n\\n[Votre Nom]\"}\n"
     ]
    }
   ],
   "source": [
    "premier = tool_calls[0]['args']\n",
    "print(premier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8279b899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour,\n",
      "\n",
      "Merci pour l'invitation à la réunion de demain. Je serai présent et prêt à discuter des points à l'ordre du jour. Si vous avez des documents ou des informations supplémentaires à partager avant la réunion, n'hésitez pas à me les envoyer.\n",
      "\n",
      "Cordialement,\n",
      "\n",
      "[Votre Nom]\n"
     ]
    }
   ],
   "source": [
    "premier = tool_calls[0]['args']['content']\n",
    "print(premier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d052ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f8abece",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd07b82",
   "metadata": {},
   "source": [
    "![basic_prompt](img/tool_call.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a210cb9c",
   "metadata": {},
   "source": [
    "## Workflows\n",
    "\n",
    "Il existe de nombreux schémas pour construire des applications avec des LLMs.\n",
    "\n",
    "Nous pouvons intégrer des appels LLM dans des workflows prédéfinis, ce qui donne au système plus d’autonomie pour prendre des décisions.\n",
    "\n",
    "Par exemple, nous pourrions ajouter une étape de routage pour déterminer s’il faut ou non rédiger un email.\n",
    "\n",
    "## Agents\n",
    "\n",
    "Nous pouvons encore augmenter l’autonomie en permettant au LLM de diriger lui-même de façon dynamique l’utilisation de ses outils.\n",
    "\n",
    "Les agents sont généralement implémentés sous forme d’appels d’outils dans une boucle, où la sortie de chaque appel d’outil sert à informer la prochaine action.\n",
    "\n",
    "![agent_example](img/agent_example.png)\n",
    "\n",
    "Les agents conviennent bien aux problèmes ouverts, où il est difficile de prévoir à l’avance les étapes exactes nécessaires.\n",
    "\n",
    "Les workflows sont souvent adaptés lorsque le flux de contrôle peut être facilement défini à l’avance.\n",
    "\n",
    "![workflow_v_agent](img/workflow_v_agent.png)\n",
    "\n",
    "## Qu’est-ce que LangGraph ?\n",
    "\n",
    "LangGraph fournit une infrastructure de bas niveau qui sert de support à n’importe quel workflow ou agent.\n",
    "\n",
    "Il n’abstrait pas les prompts ni l’architecture, et apporte plusieurs avantages :\n",
    "\n",
    "- **Contrôle** : simplifier la définition et/ou la combinaison d’agents et de workflows.\n",
    "- **Persistance** : offrir un moyen de conserver l’état d’un graphe, ce qui permet d’ajouter de la mémoire et d’intégrer l’humain dans la boucle.\n",
    "- **Tests, Débogage et Déploiement** : fournir une rampe d’accès simple pour tester, déboguer et déployer des applications.\n",
    "\n",
    "### Contrôle\n",
    "\n",
    "LangGraph permet de définir une application comme un graphe avec :\n",
    "\n",
    "1. **État (State)** : quelles informations devons-nous suivre tout au long de l’application ?\n",
    "2. **Nœuds (Nodes)** : comment voulons-nous mettre à jour ces informations au fil de l’application ?\n",
    "3. **Arêtes (Edges)** : comment voulons-nous relier ces nœuds entre eux ?\n",
    "\n",
    "Nous pouvons utiliser la classe `StateGraph` pour initialiser un graphe LangGraph avec un objet `State`.\n",
    "\n",
    "État (`State`) définit le schéma des informations que nous voulons suivre tout au long de l’application.\n",
    "\n",
    "Cela peut être n’importe quel objet compatible avec `getattr()` en Python, comme un dictionnaire, une dataclass ou un objet Pydantic :\n",
    "\n",
    "* TypedDict : le plus rapide mais ne prend pas en charge les valeurs par défaut.\n",
    "\n",
    "* Dataclass : quasiment aussi rapide, prend en charge la syntaxe par points (state.foo) et accepte des valeurs par défaut.\n",
    "\n",
    "* Pydantic : plus lent (surtout avec des validateurs personnalisés) mais fournit une validation stricte des types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9fc1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class StateSchema(TypedDict):\n",
    "    request: str\n",
    "    email: str\n",
    "\n",
    "workflow = StateGraph(StateSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9242d261",
   "metadata": {},
   "source": [
    "Chaque nœud est simplement une fonction Python ou du code TypeScript. Cela nous donne un contrôle total sur la logique à l’intérieur de chaque nœud.\n",
    "\n",
    "Ils reçoivent l’état courant et renvoient un dictionnaire pour mettre à jour cet état.\n",
    "\n",
    "Par défaut, les clés de l’état sont écrasées.\n",
    "\n",
    "Cependant, il est possible de définir une logique de mise à jour personnalisée.\n",
    "\n",
    "![nodes_edges](img/nodes_edges.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d23ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_email_node(state: StateSchema) -> StateSchema:\n",
    "    # Imperative code that processes the request\n",
    "    output = model_with_tools.invoke(state[\"request\"])\n",
    "    args = output.tool_calls[0]['args']\n",
    "    email = write_email.invoke(args)\n",
    "    return {\"email\": email}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fbf909",
   "metadata": {},
   "source": [
    "Les arêtes relient les nœuds entre eux.\n",
    "\n",
    "Nous spécifions le flux de contrôle en ajoutant des arêtes et des nœuds à notre graphe d’état."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa0773",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(StateSchema)\n",
    "workflow.add_node(\"write_email_node\", write_email_node)\n",
    "workflow.add_edge(START, \"write_email_node\")\n",
    "workflow.add_edge(\"write_email_node\", END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d4b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke({\"request\": \"Draft a response to my boss (boss@company.ai) about tomorrow's meeting\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf2498",
   "metadata": {},
   "source": [
    "Le routage entre les nœuds peut se faire de manière conditionnelle en utilisant une simple fonction.\n",
    "\n",
    "La valeur de retour de cette fonction est utilisée comme nom du nœud (ou liste de nœuds) vers lequel envoyer l’état suivant.\n",
    "\n",
    "Il est également possible de fournir un dictionnaire qui associe la sortie de `should_continue` au nom du nœud suivant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892b53f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import MessagesState\n",
    "from email_assistant.utils import show_graph\n",
    "\n",
    "def call_llm(state: MessagesState) -> MessagesState:\n",
    "    \"\"\"Run LLM\"\"\"\n",
    "\n",
    "    output = model_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [output]}\n",
    "\n",
    "def run_tool(state: MessagesState):\n",
    "    \"\"\"Performs the tool call\"\"\"\n",
    "\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        observation = write_email.invoke(tool_call[\"args\"])\n",
    "        result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": tool_call[\"id\"]})\n",
    "    return {\"messages\": result}\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"run_tool\", \"__end__\"]:\n",
    "    \"\"\"Route to tool handler, or end if Done tool called\"\"\"\n",
    "    \n",
    "    # Get the last message\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # If the last message is a tool call, check if it's a Done tool call\n",
    "    if last_message.tool_calls:\n",
    "        return \"run_tool\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"call_llm\", call_llm)\n",
    "workflow.add_node(\"run_tool\", run_tool)\n",
    "workflow.add_edge(START, \"call_llm\")\n",
    "workflow.add_conditional_edges(\"call_llm\", should_continue, {\"run_tool\": \"run_tool\", END: END})\n",
    "workflow.add_edge(\"run_tool\", END)\n",
    "\n",
    "# Run the workflow\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c10e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0208774",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Draft a response to my boss (boss@company.ai) confirming that I want to attend Interrupt!\"}]})\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc050366",
   "metadata": {},
   "source": [
    "Avec ces composants de bas niveau, il est possible de construire une grande variété de workflows et d’agents. Voyez [ce tutoriel !](https://langchain-ai.github.io/langgraph/tutorials/workflows/#orchestrator-worker)\n",
    "\n",
    "Comme les agents constituent un schéma très répandu, LangGraph propose une abstraction d’agent déjà prête.\n",
    "\n",
    "Avec la méthode préconstruite de LangGraph, il suffit simplement de fournir le LLM, les outils et le prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ac6b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[write_email],\n",
    "    prompt=\"Respond to the user's request using the tools provided.\"  \n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Rédige une réponse à mon patron (boss@company.ai) confirmant que je souhaite assister à Interrupt !\"}]}\n",
    ")\n",
    "\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c687bb2",
   "metadata": {},
   "source": [
    "### Persistance\n",
    "#### Threads\n",
    "\n",
    "Il peut être très utile de permettre aux agents de faire une pause pendant des tâches longues.\n",
    "\n",
    "LangGraph dispose d’une couche de persistance intégrée, mise en œuvre au moyen de checkpointers, pour rendre cela possible.\n",
    "\n",
    "Lorsque vous compilez un graphe avec un checkpointer, celui-ci enregistre un point de contrôle de l’état du graphe à chaque étape.\n",
    "\n",
    "Les points de contrôle sont enregistrés dans un thread, qui peut être consulté une fois l’exécution du graphe terminée.\n",
    "\n",
    "\n",
    "![checkpointer](img/checkpoints.png)\n",
    "\n",
    "On compile le graphe avec un checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc492ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[write_email],\n",
    "    prompt=\"Respond to the user's request using the tools provided.\",\n",
    "    checkpointer=InMemorySaver()\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What are some good practices for writing emails?\"}]}, config)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the latest state snapshot\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "state = agent.get_state(config)\n",
    "for message in state.values['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c628f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the conversation\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Good, let's use lesson 3 to craft a response to my boss confirming that I want to attend Interrupt\"}]}, config)\n",
    "for m in result['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae29cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the conversation\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"I like this, let's write the email to boss@company.ai\"}]}, config)\n",
    "for m in result['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ae752a",
   "metadata": {},
   "source": [
    "#### Interruptions\n",
    "\n",
    "Dans LangGraph, nous pouvons également utiliser des interruptions pour arrêter l’exécution d’un graphe à des points précis.\n",
    "\n",
    "Cela sert souvent à recueillir une entrée auprès d’un utilisateur, puis à poursuivre l’exécution avec cette entrée collectée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767832b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from langgraph.types import Command, interrupt\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "class State(TypedDict):\n",
    "    input: str\n",
    "    user_feedback: str\n",
    "\n",
    "def step_1(state):\n",
    "    print(\"---Step 1---\")\n",
    "    pass\n",
    "\n",
    "def human_feedback(state):\n",
    "    print(\"---human_feedback---\")\n",
    "    feedback = interrupt(\"Please provide feedback:\")\n",
    "    return {\"user_feedback\": feedback}\n",
    "\n",
    "def step_3(state):\n",
    "    print(\"---Step 3---\")\n",
    "    pass\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"step_1\", step_1)\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "builder.add_node(\"step_3\", step_3)\n",
    "builder.add_edge(START, \"step_1\")\n",
    "builder.add_edge(\"step_1\", \"human_feedback\")\n",
    "builder.add_edge(\"human_feedback\", \"step_3\")\n",
    "builder.add_edge(\"step_3\", END)\n",
    "\n",
    "# Set up memory\n",
    "memory = InMemorySaver()\n",
    "\n",
    "# Add\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49c9a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd22ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "initial_input = {\"input\": \"hello world\"}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"updates\"):\n",
    "    print(event)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc094dba",
   "metadata": {},
   "source": [
    "Pour reprendre après une interruption, nous pouvons utiliser l’objet `Command`.\n",
    "\n",
    "Nous l’utiliserons pour relancer le graphe à partir de l’état interrompu, en passant la valeur à retourner depuis l’appel d’interruption afin de poursuivre l’exécution avec `resume`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e97c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the graph execution\n",
    "for event in graph.stream(\n",
    "    Command(resume=\"go to step 3!\"),\n",
    "    thread,\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(event)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e58981a",
   "metadata": {},
   "source": [
    "### Traçage\n",
    "\n",
    "Lorsque nous utilisons LangChain ou LangGraph, la journalisation avec LangSmith fonctionne immédiatement si les variables d’environnement suivantes sont définies :\n",
    "\n",
    "```\n",
    "export LANGSMITH_TRACING=true\n",
    "export LANGSMITH_API_KEY=\"<your-langsmith-api-key>\"\n",
    "```\n",
    "\n",
    "Voici le trace LangSmith issu de l’exécution de l’agent ci-dessus :\n",
    "\n",
    "\n",
    "Nous pouvons voir que l’agent est capable de poursuivre la conversation à partir de l’état précédent parce que nous avons utilisé un checkpointer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b6871c",
   "metadata": {},
   "source": [
    "### Déploiement\n",
    "\n",
    "Nous pouvons également déployer notre graphe en utilisant la **LangGraph Platform.**\n",
    "\n",
    "Cela crée un serveur **avec une API** que nous pouvons utiliser pour interagir avec notre graphe, ainsi qu’un IDE interactif appelé **LangGraph Studio.**\n",
    "\n",
    "Il suffit de s’assurer que notre projet a une structure comme celle-ci :\n",
    "\n",
    "```\n",
    "my-app/\n",
    "├── src/email_assistant   # tout le code du projet se trouve ici\n",
    "│   └── langgraph101.py   # code de construction du graphe\n",
    "├── .env                  # variables d’environnement\n",
    "├── langgraph.json        # fichier de configuration de LangGraph\n",
    "└── pyproject.toml        # dépendances du projet\n",
    "```\n",
    "\n",
    "Le fichier `langgraph.json` spécifie les dépendances, les graphes, les variables d’environnement et les autres paramètres nécessaires pour démarrer un serveur LangGraph.\n",
    "\n",
    "Pour tester cela, déployons `langgraph_101.py`. Nous l’avons déjà déclaré dans le fichier `langgraph.json` de ce dépôt :\n",
    "\n",
    "\"langgraph101\": \"./src/email_assistant/langgraph_101.py:app\"\n",
    "\n",
    "\n",
    "**Options de déploiement avec LangGraph Platform**\n",
    "\n",
    "Il existe plusieurs options de déploiement :\n",
    "\n",
    "* Les déploiements locaux peuvent être lancés avec `langgraph dev` depuis le répertoire racine du dépôt. Les points de contrôle sont alors enregistrés dans le système de fichiers local.\n",
    "\n",
    "* Il existe également différentes options [auto-hébergées.](https://docs.langchain.com/langgraph-platform/deployment-options#other-deployment-options)\n",
    "\n",
    "* Pour les déploiements hébergés, les points de contrôle sont sauvegardés dans Postgres en utilisant un checkpointer Postgres.\n",
    "\n",
    "Test\n",
    "\n",
    "Demande : Rédige une réponse à mon patron (boss@company.ai\n",
    ") confirmant que je souhaite assister à Interrupt !\n",
    "\n",
    "Ici, nous pouvons voir une visualisation du graphe ainsi que l’état du graphe dans Studio.\n",
    "\n",
    "![langgraph_studio](img/langgraph_studio.png)\n",
    "\n",
    "Vous pouvez également consulter la documentation de l’API pour le déploiement local ici :\n",
    "\n",
    "http://127.0.0.1:2024/docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "email_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
