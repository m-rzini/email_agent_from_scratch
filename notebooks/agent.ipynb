{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e5f1f52",
   "metadata": {},
   "source": [
    "# Constuire des agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5179f65a",
   "metadata": {},
   "source": [
    "Nous allons construire un email assistant Ã  partir de zÃ©ro, en commenÃ§ant ici par 1) lâ€™agent architecture (avec LangGraph), puis enchaÃ®nant avec 2) testing (avec LangSmith), 3) human-in-the-loop, et 4) memory.\n",
    "\n",
    "Ce diagramme montre comment ces Ã©lÃ©ments vont sâ€™imbriquer ensemble :\n",
    "\n",
    "![overview-img](img/overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907efea5",
   "metadata": {},
   "source": [
    "### Charger les variables dâ€™environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e336735b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b3de9f",
   "metadata": {},
   "source": [
    "## Tool Definition\n",
    "CommenÃ§ons par dÃ©finir quelques outils simples que notre email assistant utilisera grÃ¢ce au dÃ©corateur `@tool` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c936d77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Write and send an email.\"\"\"\n",
    "    # Placeholder response - in real app would send email\n",
    "    return f\"Email sent to {to} with subject '{subject}' and content: {content}\"\n",
    "\n",
    "@tool\n",
    "def schedule_meeting(\n",
    "    attendees: list[str], subject: str, duration_minutes: int, preferred_day: datetime, start_time: int\n",
    ") -> str:\n",
    "    \"\"\"Schedule a calendar meeting.\"\"\"\n",
    "    # Placeholder response - in real app would check calendar and schedule\n",
    "    date_str = preferred_day.strftime(\"%A, %B %d, %Y\")\n",
    "    return f\"Meeting '{subject}' scheduled on {date_str} at {start_time} for {duration_minutes} minutes with {len(attendees)} attendees\"\n",
    "\n",
    "@tool\n",
    "def check_calendar_availability(day: str) -> str:\n",
    "    \"\"\"Check calendar availability for a given day.\"\"\"\n",
    "    # Placeholder response - in real app would check actual calendar\n",
    "    return f\"Available times on {day}: 9:00 AM, 2:00 PM, 4:00 PM\"\n",
    "\n",
    "@tool\n",
    "class Done(BaseModel):\n",
    "      \"\"\"E-mail has been sent.\"\"\"\n",
    "      done: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5048cd17",
   "metadata": {},
   "source": [
    "## Building our email assistant\n",
    "\n",
    "Nous allons combiner un router et un agent pour construire notre email assistant.\n",
    "\n",
    "![agent_workflow_img](img/email_workflow.png)\n",
    "\n",
    "### Router\n",
    "\n",
    "Lâ€™Ã©tape de routing gÃ¨re la dÃ©cision de triage.\n",
    "\n",
    "Le **triage router** se concentre uniquement sur la dÃ©cision de triage, tandis que lâ€™agent se concentre uniquement sur la rÃ©ponse.\n",
    "\n",
    "### State\n",
    "\n",
    "Lors de la construction dâ€™un agent, il est important de rÃ©flÃ©chir aux informations que vous souhaitez suivre dans le temps. Nous utiliserons lâ€™objet prÃ©-construit `MessagesState` de LangGraph, qui est simplement un dictionnaire avec une clÃ© `messages` dont la logique de mise Ã  jour consiste Ã  ajouter (append) les messages renvoyÃ©s par les nÅ“uds. Toutefois, LangGraph offre la flexibilitÃ© de suivre dâ€™autres informations. Nous dÃ©finirons un `State` personnalisÃ© qui Ã©tend `MessagesState` et ajoute une clÃ© `classification_decision`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b31ed823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class State(MessagesState):\n",
    "    # We can add a specific key to our state for the email input\n",
    "    email_input: dict\n",
    "    classification_decision: Literal[\"ignore\", \"respond\", \"notify\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c15080",
   "metadata": {},
   "source": [
    "#### Triage node\n",
    "\n",
    "Nous dÃ©finissons une fonction python avec notre logique de **triage routing.**\n",
    "\n",
    "Pour cela, nous utilisons des structured outputs avec un modÃ¨le **Pydantic**, particuliÃ¨rement utile pour dÃ©finir des **structured output schemas** grÃ¢ce aux indications de type (type hints) et Ã  la validation. Les descriptions dans le modÃ¨le **Pydantic** sont importantes, car elles sont transmises au LLM sous forme de JSON schema afin dâ€™orienter la **output coercion**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6933b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from email_assistant.utils import parse_email, format_email_markdown\n",
    "from email_assistant.prompts import triage_system_prompt, triage_user_prompt, default_triage_instructions, default_background\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import END\n",
    "from langgraph.types import Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da7d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.markdown import Markdown\n",
    "Markdown(triage_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac1339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(triage_user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9758b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(default_background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc2fbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(default_triage_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe389b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RouterSchema(BaseModel):\n",
    "    \"\"\"Analyze the unread email and route it according to its content.\"\"\"\n",
    "\n",
    "    reasoning: str = Field(\n",
    "        description=\"Step-by-step reasoning behind the classification.\"\n",
    "    )\n",
    "    classification: Literal[\"ignore\", \"respond\", \"notify\"] = Field(\n",
    "        description=\"The classification of an email: 'ignore' for irrelevant emails, \"\n",
    "        \"'notify' for important information that doesn't need a response, \"\n",
    "        \"'respond' for emails that need a reply\",\n",
    "    )\n",
    "\n",
    "# Initialize the LLM for use with router / structured output\n",
    "llm = init_chat_model(\"openai:gpt-4.1\", temperature=0.0)\n",
    "llm_router = llm.with_structured_output(RouterSchema) \n",
    "\n",
    "def triage_router(state: State) -> Command[Literal[\"response_agent\", \"__end__\"]]:\n",
    "    \"\"\"Analyze email content to decide if we should respond, notify, or ignore.\"\"\"\n",
    "    \n",
    "    author, to, subject, email_thread = parse_email(state[\"email_input\"])\n",
    "    system_prompt = triage_system_prompt.format(\n",
    "        background=default_background,\n",
    "        triage_instructions=default_triage_instructions\n",
    "    )\n",
    "\n",
    "    user_prompt = triage_user_prompt.format(\n",
    "        author=author, to=to, subject=subject, email_thread=email_thread\n",
    "    )\n",
    "\n",
    "    result = llm_router.invoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    if result.classification == \"respond\":\n",
    "        print(\"ðŸ“§ Classification: RESPOND - This email requires a response\")\n",
    "        goto = \"response_agent\"\n",
    "        update = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Respond to the email: \\n\\n{format_email_markdown(subject, author, to, email_thread)}\",\n",
    "                }\n",
    "            ],\n",
    "            \"classification_decision\": result.classification,\n",
    "        }\n",
    "        \n",
    "    elif result.classification == \"ignore\":\n",
    "        print(\"ðŸš« Classification: IGNORE - This email can be safely ignored\")\n",
    "        goto = END\n",
    "        update =  {\n",
    "            \"classification_decision\": result.classification,\n",
    "        }\n",
    "        \n",
    "    elif result.classification == \"notify\":\n",
    "        print(\"ðŸ”” Classification: NOTIFY - This email contains important information\")\n",
    "        # For now, we go to END. But we will add to this later!\n",
    "        goto = END\n",
    "        update = {\n",
    "            \"classification_decision\": result.classification,\n",
    "        }\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Invalid classification: {result.classification}\")\n",
    "    return Command(goto=goto, update=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50cc723",
   "metadata": {},
   "source": [
    "Command objects\n",
    "\n",
    "Nous utilisons des Command objects dans LangGraph Ã  la fois pour mettre Ã  jour le state et sÃ©lectionner le next node Ã  visiter. Câ€™est une alternative utile aux edges.\n",
    "\n",
    "### Agent\n",
    "\n",
    "Maintenant, construisons lâ€™agent.\n",
    "\n",
    "#### LLM node\n",
    "\n",
    "Ici, nous dÃ©finissons le LLM decision-making node. Ce nÅ“ud reÃ§oit le current state, appelle le LLM, et met Ã  jour `messages` avec la sortie du LLM.\n",
    "\n",
    "Nous enforÃ§ons lâ€™usage des tools avec OpenAI en rÃ©glant `tool_choice=\"required`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8796f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from email_assistant.tools.default.prompt_templates import AGENT_TOOLS_PROMPT\n",
    "from email_assistant.prompts import agent_system_prompt, default_response_preferences, default_cal_preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7376f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(AGENT_TOOLS_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30d2f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(agent_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6e5259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all tools\n",
    "tools = [write_email, schedule_meeting, check_calendar_availability, Done]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "# Initialize the LLM, enforcing tool use\n",
    "llm = init_chat_model(\"openai:gpt-4.1\", temperature=0.0)\n",
    "llm_with_tools = llm.bind_tools(tools, tool_choice=\"any\")\n",
    "\n",
    "def llm_call(state: State):\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            # Invoke the LLM\n",
    "            llm_with_tools.invoke(\n",
    "                # Add the system prompt\n",
    "                [   \n",
    "                    {\"role\": \"system\", \"content\": agent_system_prompt.format(\n",
    "                        tools_prompt=AGENT_TOOLS_PROMPT,\n",
    "                        background=default_background,\n",
    "                        response_preferences=default_response_preferences,\n",
    "                        cal_preferences=default_cal_preferences, \n",
    "                    )}\n",
    "                ]\n",
    "                # Add the current messages to the prompt\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8d4bf6",
   "metadata": {},
   "source": [
    "#### Tool handler node\n",
    "\n",
    "AprÃ¨s que le LLM a pris une dÃ©cision, nous devons exÃ©cuter le tool choisi.\n",
    "\n",
    "Le nÅ“ud `tool_handler` exÃ©cute le tool. Nous voyons que les nodes peuvent update le graph state pour capturer toute modification dâ€™Ã©tat importante, comme la classification decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d7c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_handler(state: State):\n",
    "    \"\"\"Performs the tool call.\"\"\"\n",
    "\n",
    "    # List for tool messages\n",
    "    result = []\n",
    "    \n",
    "    # Iterate through tool calls\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        # Get the tool\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        # Run it\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        # Create a tool message\n",
    "        result.append({\"role\": \"tool\", \"content\" : observation, \"tool_call_id\": tool_call[\"id\"]})\n",
    "    \n",
    "    # Add it to our messages\n",
    "    return {\"messages\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a457e",
   "metadata": {},
   "source": [
    "#### Conditional Routing\n",
    "\n",
    "Notre agent doit dÃ©cider quand continuer Ã  utiliser des tools et quand sâ€™arrÃªter. Cette fonction de conditional routing oriente lâ€™agent soit Ã  continue, soit Ã  terminate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01824e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: State) -> Literal[\"tool_handler\", \"__end__\"]:\n",
    "    \"\"\"Route to tool handler, or end if Done tool called.\"\"\"\n",
    "    \n",
    "    # Get the last message\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # Check if it's a Done tool call\n",
    "    if last_message.tool_calls:\n",
    "        for tool_call in last_message.tool_calls: \n",
    "            if tool_call[\"name\"] == \"Done\":\n",
    "                return END\n",
    "            else:\n",
    "                return \"tool_handler\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71492278",
   "metadata": {},
   "source": [
    "#### Agent Graph\n",
    "\n",
    "Enfin, nous pouvons assembler tous les composants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7726f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from email_assistant.utils import show_graph\n",
    "\n",
    "# Build workflow\n",
    "overall_workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "overall_workflow.add_node(\"llm_call\", llm_call)\n",
    "overall_workflow.add_node(\"tool_handler\", tool_handler)\n",
    "\n",
    "# Add edges\n",
    "overall_workflow.add_edge(START, \"llm_call\")\n",
    "overall_workflow.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tool_handler\": \"tool_handler\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "overall_workflow.add_edge(\"tool_handler\", \"llm_call\")\n",
    "\n",
    "# Compile the agent\n",
    "agent = overall_workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c615a2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View\n",
    "show_graph(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f5a78",
   "metadata": {},
   "source": [
    "Cela crÃ©e un graph qui :\n",
    "\n",
    "1. Starts with an LLM decision\n",
    "\n",
    "2. Conditionally routes vers tool execution ou termination\n",
    "\n",
    "3. AprÃ¨s tool execution, revient au LLM pour la next decision\n",
    "\n",
    "4. Repeats jusquâ€™Ã  completion ou si aucun tool nâ€™est appelÃ©\n",
    "\n",
    "### Combine workflow with our agent\n",
    "\n",
    "Nous pouvons combine le router et lâ€™agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a2d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_workflow = (\n",
    "    StateGraph(State)\n",
    "    .add_node(triage_router)\n",
    "    .add_node(\"response_agent\", agent)\n",
    "    .add_edge(START, \"triage_router\")\n",
    ").compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd172fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(overall_workflow, xray=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b43077",
   "metadata": {},
   "source": [
    "Câ€™est une composition de plus haut niveau oÃ¹ :\n",
    "\n",
    "1. Dâ€™abord, le triage router analyse lâ€™email\n",
    "\n",
    "2. Si nÃ©cessaire, le response agent se charge de rÃ©diger une rÃ©ponse\n",
    "\n",
    "3. Le workflow se termine soit lorsque le triage dÃ©cide quâ€™aucune rÃ©ponse nâ€™est nÃ©cessaire, soit lorsque le response agent a terminÃ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e8f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_input = {\n",
    "    \"author\": \"System Admin <sysadmin@company.com>\",\n",
    "    \"to\": \"Development Team <dev@company.com>\",\n",
    "    \"subject\": \"Scheduled maintenance - database downtime\",\n",
    "    \"email_thread\": \"Hi team,\\n\\nThis is a reminder that we'll be performing scheduled maintenance on the production database tonight from 2AM to 4AM EST. During this time, all database services will be unavailable.\\n\\nPlease plan your work accordingly and ensure no critical deployments are scheduled during this window.\\n\\nThanks,\\nSystem Admin Team\"\n",
    "}\n",
    "\n",
    "# Run the agent\n",
    "response = overall_workflow.invoke({\"email_input\": email_input})\n",
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d4b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_input = {\n",
    "  \"author\": \"Alice Smith <alice.smith@company.com>\",\n",
    "  \"to\": \"John Doe <john.doe@company.com>\",\n",
    "  \"subject\": \"Quick question about API documentation\",\n",
    "  \"email_thread\": \"Hi John,\\nI was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\\nSpecifically, I'm looking at:\\n- /auth/refresh\\n- /auth/validate\\nThanks!\\nAlice\"\n",
    "}\n",
    "\n",
    "# Run the agent\n",
    "response = overall_workflow.invoke({\"email_input\": email_input})\n",
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1601090a",
   "metadata": {},
   "source": [
    "## Testing with Local Deployment\n",
    "\n",
    "Vous pouvez trouver le fichier de notre agent dans le rÃ©pertoire :\n",
    "\n",
    "* `src/email_assistant/email_assistant.py`\n",
    "\n",
    "\n",
    "Vous pouvez les tester en local dans LangGraph Studio en exÃ©cutant :\n",
    "\n",
    "```\n",
    "! langgraph dev\n",
    "```\n",
    "\n",
    "Example e-mail you can test\n",
    "\n",
    "Exemple dâ€™email que vous pouvez tester :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43249e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"author\": \"Alice Smith <alice.smith@company.com>\",\n",
    "  \"to\": \"John Doe <john.doe@company.com>\",\n",
    "  \"subject\": \"Quick question about API documentation\",\n",
    "  \"email_thread\": \"Hi John,\\nI was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\\nSpecifically, I'm looking at:\\n- /auth/refresh\\n- /auth/validate\\nThanks!\\nAlice\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7cc99b",
   "metadata": {},
   "source": [
    "![studio-img](img/studio.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2294cf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "email_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
