{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e5f1f52",
   "metadata": {},
   "source": [
    "# Constuire des agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5179f65a",
   "metadata": {},
   "source": [
    "Nous allons construire un email assistant √† partir de z√©ro, en commen√ßant ici par 1) l‚Äôagent architecture (avec LangGraph), puis encha√Ænant avec 2) testing (avec LangSmith), 3) human-in-the-loop, et 4) memory.\n",
    "\n",
    "Ce diagramme montre comment ces √©l√©ments vont s‚Äôimbriquer ensemble :\n",
    "\n",
    "![overview-img](img/overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907efea5",
   "metadata": {},
   "source": [
    "### Charger les variables d‚Äôenvironnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e336735b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b3de9f",
   "metadata": {},
   "source": [
    "## Tool Definition\n",
    "Commen√ßons par d√©finir quelques outils simples que notre email assistant utilisera gr√¢ce au d√©corateur `@tool` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c936d77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Write and send an email.\"\"\"\n",
    "    # Placeholder response - in real app would send email\n",
    "    return f\"Email sent to {to} with subject '{subject}' and content: {content}\"\n",
    "\n",
    "@tool\n",
    "def schedule_meeting(\n",
    "    attendees: list[str], subject: str, duration_minutes: int, preferred_day: datetime, start_time: int\n",
    ") -> str:\n",
    "    \"\"\"Schedule a calendar meeting.\"\"\"\n",
    "    # Placeholder response - in real app would check calendar and schedule\n",
    "    date_str = preferred_day.strftime(\"%A, %B %d, %Y\")\n",
    "    return f\"Meeting '{subject}' scheduled on {date_str} at {start_time} for {duration_minutes} minutes with {len(attendees)} attendees\"\n",
    "\n",
    "@tool\n",
    "def check_calendar_availability(day: str) -> str:\n",
    "    \"\"\"Check calendar availability for a given day.\"\"\"\n",
    "    # Placeholder response - in real app would check actual calendar\n",
    "    return f\"Available times on {day}: 9:00 AM, 2:00 PM, 4:00 PM\"\n",
    "\n",
    "@tool\n",
    "class Done(BaseModel):\n",
    "      \"\"\"E-mail has been sent.\"\"\"\n",
    "      done: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5048cd17",
   "metadata": {},
   "source": [
    "## Building our email assistant\n",
    "\n",
    "Nous allons combiner un router et un agent pour construire notre email assistant.\n",
    "\n",
    "![agent_workflow_img](img/email_workflow.png)\n",
    "\n",
    "### Router\n",
    "\n",
    "L‚Äô√©tape de routing g√®re la d√©cision de triage.\n",
    "\n",
    "Le **triage router** se concentre uniquement sur la d√©cision de triage, tandis que l‚Äôagent se concentre uniquement sur la r√©ponse.\n",
    "\n",
    "### State\n",
    "\n",
    "Lors de la construction d‚Äôun agent, il est important de r√©fl√©chir aux informations que vous souhaitez suivre dans le temps. Nous utiliserons l‚Äôobjet pr√©-construit `MessagesState` de LangGraph, qui est simplement un dictionnaire avec une cl√© `messages` dont la logique de mise √† jour consiste √† ajouter (append) les messages renvoy√©s par les n≈ìuds. Toutefois, LangGraph offre la flexibilit√© de suivre d‚Äôautres informations. Nous d√©finirons un `State` personnalis√© qui √©tend `MessagesState` et ajoute une cl√© `classification_decision`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b31ed823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class State(MessagesState):\n",
    "    # We can add a specific key to our state for the email input\n",
    "    email_input: dict\n",
    "    classification_decision: Literal[\"ignore\", \"respond\", \"notify\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c15080",
   "metadata": {},
   "source": [
    "#### Triage node\n",
    "\n",
    "Nous d√©finissons une fonction python avec notre logique de **triage routing.**\n",
    "\n",
    "Pour cela, nous utilisons des structured outputs avec un mod√®le **Pydantic**, particuli√®rement utile pour d√©finir des **structured output schemas** gr√¢ce aux indications de type (type hints) et √† la validation. Les descriptions dans le mod√®le **Pydantic** sont importantes, car elles sont transmises au LLM sous forme de JSON schema afin d‚Äôorienter la **output coercion**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6933b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from email_assistant.utils import parse_email, format_email_markdown\n",
    "from email_assistant.prompts import triage_system_prompt, triage_user_prompt, default_triage_instructions, default_background\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import END\n",
    "from langgraph.types import Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da7d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.markdown import Markdown\n",
    "Markdown(triage_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac1339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(triage_user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9758b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(default_background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc2fbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(default_triage_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe389b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RouterSchema(BaseModel):\n",
    "    \"\"\"Analyze the unread email and route it according to its content.\"\"\"\n",
    "\n",
    "    reasoning: str = Field(\n",
    "        description=\"Step-by-step reasoning behind the classification.\"\n",
    "    )\n",
    "    classification: Literal[\"ignore\", \"respond\", \"notify\"] = Field(\n",
    "        description=\"The classification of an email: 'ignore' for irrelevant emails, \"\n",
    "        \"'notify' for important information that doesn't need a response, \"\n",
    "        \"'respond' for emails that need a reply\",\n",
    "    )\n",
    "\n",
    "# Initialize the LLM for use with router / structured output\n",
    "llm = init_chat_model(\"openai:gpt-4.1\", temperature=0.0)\n",
    "llm_router = llm.with_structured_output(RouterSchema) \n",
    "\n",
    "def triage_router(state: State) -> Command[Literal[\"response_agent\", \"__end__\"]]:\n",
    "    \"\"\"Analyze email content to decide if we should respond, notify, or ignore.\"\"\"\n",
    "    \n",
    "    author, to, subject, email_thread = parse_email(state[\"email_input\"])\n",
    "    system_prompt = triage_system_prompt.format(\n",
    "        background=default_background,\n",
    "        triage_instructions=default_triage_instructions\n",
    "    )\n",
    "\n",
    "    user_prompt = triage_user_prompt.format(\n",
    "        author=author, to=to, subject=subject, email_thread=email_thread\n",
    "    )\n",
    "\n",
    "    result = llm_router.invoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    if result.classification == \"respond\":\n",
    "        print(\"üìß Classification: RESPOND - This email requires a response\")\n",
    "        goto = \"response_agent\"\n",
    "        update = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Respond to the email: \\n\\n{format_email_markdown(subject, author, to, email_thread)}\",\n",
    "                }\n",
    "            ],\n",
    "            \"classification_decision\": result.classification,\n",
    "        }\n",
    "        \n",
    "    elif result.classification == \"ignore\":\n",
    "        print(\"üö´ Classification: IGNORE - This email can be safely ignored\")\n",
    "        goto = END\n",
    "        update =  {\n",
    "            \"classification_decision\": result.classification,\n",
    "        }\n",
    "        \n",
    "    elif result.classification == \"notify\":\n",
    "        print(\"üîî Classification: NOTIFY - This email contains important information\")\n",
    "        # For now, we go to END. But we will add to this later!\n",
    "        goto = END\n",
    "        update = {\n",
    "            \"classification_decision\": result.classification,\n",
    "        }\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Invalid classification: {result.classification}\")\n",
    "    return Command(goto=goto, update=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50cc723",
   "metadata": {},
   "source": [
    "Command objects\n",
    "\n",
    "Nous utilisons des Command objects dans LangGraph √† la fois pour mettre √† jour le state et s√©lectionner le next node √† visiter. C‚Äôest une alternative utile aux edges.\n",
    "\n",
    "### Agent\n",
    "\n",
    "Maintenant, construisons l‚Äôagent.\n",
    "\n",
    "#### LLM node\n",
    "\n",
    "Ici, nous d√©finissons le LLM decision-making node. Ce n≈ìud re√ßoit le current state, appelle le LLM, et met √† jour `messages` avec la sortie du LLM.\n",
    "\n",
    "Nous enfor√ßons l‚Äôusage des tools avec OpenAI en r√©glant `tool_choice=\"required`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8796f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from email_assistant.tools.default.prompt_templates import AGENT_TOOLS_PROMPT\n",
    "from email_assistant.prompts import agent_system_prompt, default_response_preferences, default_cal_preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7376f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(AGENT_TOOLS_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30d2f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(agent_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6e5259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all tools\n",
    "tools = [write_email, schedule_meeting, check_calendar_availability, Done]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "# Initialize the LLM, enforcing tool use\n",
    "llm = init_chat_model(\"openai:gpt-4.1\", temperature=0.0)\n",
    "llm_with_tools = llm.bind_tools(tools, tool_choice=\"any\")\n",
    "\n",
    "def llm_call(state: State):\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            # Invoke the LLM\n",
    "            llm_with_tools.invoke(\n",
    "                # Add the system prompt\n",
    "                [   \n",
    "                    {\"role\": \"system\", \"content\": agent_system_prompt.format(\n",
    "                        tools_prompt=AGENT_TOOLS_PROMPT,\n",
    "                        background=default_background,\n",
    "                        response_preferences=default_response_preferences,\n",
    "                        cal_preferences=default_cal_preferences, \n",
    "                    )}\n",
    "                ]\n",
    "                # Add the current messages to the prompt\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8d4bf6",
   "metadata": {},
   "source": [
    "#### Tool handler node\n",
    "\n",
    "Apr√®s que le LLM a pris une d√©cision, nous devons ex√©cuter le tool choisi.\n",
    "\n",
    "Le n≈ìud `tool_handler` ex√©cute le tool. Nous voyons que les nodes peuvent update le graph state pour capturer toute modification d‚Äô√©tat importante, comme la classification decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d7c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_handler(state: State):\n",
    "    \"\"\"Performs the tool call.\"\"\"\n",
    "\n",
    "    # List for tool messages\n",
    "    result = []\n",
    "    \n",
    "    # Iterate through tool calls\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        # Get the tool\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        # Run it\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        # Create a tool message\n",
    "        result.append({\"role\": \"tool\", \"content\" : observation, \"tool_call_id\": tool_call[\"id\"]})\n",
    "    \n",
    "    # Add it to our messages\n",
    "    return {\"messages\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a457e",
   "metadata": {},
   "source": [
    "#### Conditional Routing\n",
    "\n",
    "Notre agent doit d√©cider quand continuer √† utiliser des tools et quand s‚Äôarr√™ter. Cette fonction de conditional routing oriente l‚Äôagent soit √† continue, soit √† terminate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01824e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: State) -> Literal[\"tool_handler\", \"__end__\"]:\n",
    "    \"\"\"Route to tool handler, or end if Done tool called.\"\"\"\n",
    "    \n",
    "    # Get the last message\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # Check if it's a Done tool call\n",
    "    if last_message.tool_calls:\n",
    "        for tool_call in last_message.tool_calls: \n",
    "            if tool_call[\"name\"] == \"Done\":\n",
    "                return END\n",
    "            else:\n",
    "                return \"tool_handler\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71492278",
   "metadata": {},
   "source": [
    "#### Agent Graph\n",
    "\n",
    "Enfin, nous pouvons assembler tous les composants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7726f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from email_assistant.utils import show_graph\n",
    "\n",
    "# Build workflow\n",
    "overall_workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "overall_workflow.add_node(\"llm_call\", llm_call)\n",
    "overall_workflow.add_node(\"tool_handler\", tool_handler)\n",
    "\n",
    "# Add edges\n",
    "overall_workflow.add_edge(START, \"llm_call\")\n",
    "overall_workflow.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tool_handler\": \"tool_handler\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "overall_workflow.add_edge(\"tool_handler\", \"llm_call\")\n",
    "\n",
    "# Compile the agent\n",
    "agent = overall_workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c615a2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View\n",
    "show_graph(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f5a78",
   "metadata": {},
   "source": [
    "Cela cr√©e un graph qui :\n",
    "\n",
    "1. Starts with an LLM decision\n",
    "\n",
    "2. Conditionally routes vers tool execution ou termination\n",
    "\n",
    "3. Apr√®s tool execution, revient au LLM pour la next decision\n",
    "\n",
    "4. Repeats jusqu‚Äô√† completion ou si aucun tool n‚Äôest appel√©\n",
    "\n",
    "### Combine workflow with our agent\n",
    "\n",
    "Nous pouvons combine le router et l‚Äôagent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a2d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_workflow = (\n",
    "    StateGraph(State)\n",
    "    .add_node(triage_router)\n",
    "    .add_node(\"response_agent\", agent)\n",
    "    .add_edge(START, \"triage_router\")\n",
    ").compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd172fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(overall_workflow, xray=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b43077",
   "metadata": {},
   "source": [
    "C‚Äôest une composition de plus haut niveau o√π :\n",
    "\n",
    "1. D‚Äôabord, le triage router analyse l‚Äôemail\n",
    "\n",
    "2. Si n√©cessaire, le response agent se charge de r√©diger une r√©ponse\n",
    "\n",
    "3. Le workflow se termine soit lorsque le triage d√©cide qu‚Äôaucune r√©ponse n‚Äôest n√©cessaire, soit lorsque le response agent a termin√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e8f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_input = {\n",
    "    \"author\": \"System Admin <sysadmin@company.com>\",\n",
    "    \"to\": \"Development Team <dev@company.com>\",\n",
    "    \"subject\": \"Scheduled maintenance - database downtime\",\n",
    "    \"email_thread\": \"Hi team,\\n\\nThis is a reminder that we'll be performing scheduled maintenance on the production database tonight from 2AM to 4AM EST. During this time, all database services will be unavailable.\\n\\nPlease plan your work accordingly and ensure no critical deployments are scheduled during this window.\\n\\nThanks,\\nSystem Admin Team\"\n",
    "}\n",
    "\n",
    "# Run the agent\n",
    "response = overall_workflow.invoke({\"email_input\": email_input})\n",
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d4b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_input = {\n",
    "  \"author\": \"Alice Smith <alice.smith@company.com>\",\n",
    "  \"to\": \"John Doe <john.doe@company.com>\",\n",
    "  \"subject\": \"Quick question about API documentation\",\n",
    "  \"email_thread\": \"Hi John,\\nI was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\\nSpecifically, I'm looking at:\\n- /auth/refresh\\n- /auth/validate\\nThanks!\\nAlice\"\n",
    "}\n",
    "\n",
    "# Run the agent\n",
    "response = overall_workflow.invoke({\"email_input\": email_input})\n",
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1601090a",
   "metadata": {},
   "source": [
    "## Testing with Local Deployment\n",
    "\n",
    "Vous pouvez trouver le fichier de notre agent dans le r√©pertoire :\n",
    "\n",
    "* `src/email_assistant/email_assistant.py`\n",
    "\n",
    "\n",
    "Vous pouvez les tester en local dans LangGraph Studio en ex√©cutant :\n",
    "\n",
    "```\n",
    "! langgraph dev\n",
    "```\n",
    "\n",
    "Example e-mail you can test\n",
    "\n",
    "Exemple d‚Äôemail que vous pouvez tester :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43249e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"author\": \"Alice Smith <alice.smith@company.com>\",\n",
    "  \"to\": \"John Doe <john.doe@company.com>\",\n",
    "  \"subject\": \"Quick question about API documentation\",\n",
    "  \"email_thread\": \"Hi John,\\nI was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\\nSpecifically, I'm looking at:\\n- /auth/refresh\\n- /auth/validate\\nThanks!\\nAlice\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7cc99b",
   "metadata": {},
   "source": [
    "![studio-img](img/studio.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2294cf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "email_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
